# âœï¸ AutoCorrect NLP â€” Context-Aware Spell Correction Engine

<p align="center">
  <a href="https://streamlit.io/">
    <img src="https://img.shields.io/badge/Streamlit-UI_Framework-red?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit UI"/>
  </a>
  <a href="https://www.nltk.org/">
    <img src="https://img.shields.io/badge/NLTK-Core_NLP_Tools-green?style=for-the-badge&logo=python&logoColor=white" alt="NLTK NLP Tools"/>
  </a>
</p>

This repository features a **modular, context-aware spell correction system** that simulates how modern editors (like Gmail, Notion, or smartphone keyboards) detect and fix spelling mistakes in real-time.

The pipeline combines classic NLP techniques like **Levenshtein Distance**, **language modeling**, and **semantic similarity** to provide accurate corrections from a **custom-built vocabulary** extracted from a massive **Kaggle corpus**.

---

## ğŸ“¥ Dataset Source

- ğŸ“š **Corpus**: [14 Million Word Corpus (Kaggle)](https://www.kaggle.com/datasets/luisgasparcordeiro/14-million-word-corpus-txt)
- ğŸ”¤ **Format**: Raw text (`.txt`)
- ğŸ¯ **Purpose**: Build a custom vocabulary with word frequencies

---

## ğŸ¯ Objective

- âœ… Build a vocabulary from a large, real-world corpus
- ğŸ” Correct spelling using dictionary, edit distance, and frequency
- ğŸ§  Add context-aware suggestions via similarity scoring
- ğŸ§ª Deploy via **Streamlit** UI for real-time corrections

---

## ğŸ“ Features

| Component               | Tech Stack              |
|------------------------|-------------------------|
| Corpus Preprocessing   | `re`, `nltk`            |
| Vocabulary Creation    | `Counter`, `stopwords`  |
| Edit Distance          | `textdistance`          |
| Semantic Matching      | `Levenshtein`, `Jaccard`|
| Frontend UI            | `Streamlit`             |

---

## ğŸ§­ Correction Pipeline

| Step                     | Description                                               |
|--------------------------|-----------------------------------------------------------|
| ğŸ§¹ Preprocessing          | Clean and tokenize corpus to extract vocabulary           |
| ğŸ“¦ Vocabulary Building    | Create and persist vocab + frequency dictionary (`.pkl`)  |
| ğŸ“š Word Filtering         | Remove stopwords and symbols                              |
| ğŸ§® Edit Distance Matching | Compute Jaccard or Levenshtein distances                  |
| ğŸ“Š Rank by Frequency      | Use Kaggle corpus frequency to rank suggestions            |
| ğŸ§  Semantic Suggestion    | Filter by similarity > 0.7 to suggest best alternatives    |
| ğŸ–¥ï¸ Streamlit UI           | Display correction and top 5 suggestions interactively     |

---

## ğŸ“¸ Visuals

### ğŸ”¡ AutoCorrect Main UI

<p align="center">
![AutoCorrect UI](UI/UI_AutoCorrect.PNG)
</p>

### ğŸ“ Suggestions Interface

<p align="center">
![Suggestion UI](UI/UI_AutoCorrect_Suggestions.PNG)
</p>

## ğŸ“¦ Folder Structure

```bash
autocorrect_app/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ corpus.txt                 # Large corpus text file
â”œâ”€â”€ models/
â”‚   â””â”€â”€ vocab.pkl                 # Pickled vocabulary + word freq
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ build_vocab.py            # Script to build and save vocab
â”‚   â””â”€â”€ corrector.py              # Spell suggestion and autocorrect
â”œâ”€â”€ interface.py                  # Streamlit frontend interface
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md
```

## ğŸš€ Quickstart

### ğŸ› ï¸ 1. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### ğŸ“¦ 2. Install Dependencies

```bash
pip install -r requirements.txt
python -m nltk.downloader stopwords
```

### ğŸ“š 3. Build Vocabulary (Run Once)
```python
# run in Python shell or script
from utils.build_vocab import build_vocab
build_vocab("data/enron.txt", "models/vocab.pkl")
```

### ğŸ–¥ï¸ 4. Launch Streamlit Interface
```bash
streamlit run interface.py
```

## ğŸ§¾ Sample Usage
```bash
Input:  "erors"
Output: "errors"
```

# ğŸ“Š Streamlit Interface Features

| Feature               | Description                                      |
|-----------------------|--------------------------------------------------|
| ğŸ”¡ Input Box          | Enter one misspelled word at a time              |
| ğŸ“ Suggestion Button  | See top 5 context-aware suggestions              |
| âœ… AutoCorrect Button | Automatically replace with best guess           |

---

# ğŸ§  Future Work

- âŒ¨ï¸ Real-time keyboard integration  
- ğŸŒ Multilingual dictionary support  
- ğŸ§  Transformer-based correction (e.g., BERT Masking)  
- ğŸ” Autocomplete integration with semantic search  

---

# ğŸ“š Learnings

- ğŸ“ **Edit distance + frequency** = strong baseline  
- ğŸ” **Semantic filtering** improves context matching  
- ğŸ§  **Hybrid models** (rule + data) outperform naive methods  
- âš¡ **Streamlit** accelerates UI for NLP tools  

---

# âœï¸ Author

- **Name**: Guna Venkat Doddi  
- **Project**: Part of *SSJ3-AI-Agent-Projects*  
- **Contact**: [![GitHub - Guna Venkat Doddi](https://img.shields.io/badge/GitHub-Guna--Venkat--Doddi-black?logo=github&style=flat-square)](https://github.com/Guna-Venkat)

